{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare env"
      ],
      "metadata": {
        "id": "V2jLUcuIYPhI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYJWmxchX34L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "! rm -rf audio_classification\n",
        "! mkdir audio_classification\n",
        "%cd audio_classification"
      ],
      "metadata": {
        "id": "v4XWFKxZYKS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Vitaljaz/tmp.git"
      ],
      "metadata": {
        "id": "Y6c-fVOAYNOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "aexlNfhHYXIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "mzqsOUc_YX1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "AbCn1n9HYasM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling rate\n",
        "s_rate = 8820\n",
        "n_fft = 1024\n",
        "hop_length = 128\n",
        "n_mels = 128\n",
        "\n",
        "# define directories\n",
        "base_dir = '/content/audio_classification/tmp/custom_plastic_gun_shot/plastic_bag_gun_shot'\n",
        "meta_file = os.path.join(base_dir, 'meta/meta.csv')\n",
        "audio_dir = os.path.join(base_dir, 'audio/')\n",
        "\n",
        "# To show more rows and columns without \"...\"\n",
        "pd.options.display.max_columns=999\n",
        "pd.options.display.max_rows=999"
      ],
      "metadata": {
        "id": "Y7TPxlElYcHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read CSV file"
      ],
      "metadata": {
        "id": "_UdOj9ZsYhaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load metadata\n",
        "meta_data = pd.read_csv(meta_file, delimiter=',', skiprows=0, header=0)\n",
        "print(meta_data.shape)\n",
        "display(meta_data.head())"
      ],
      "metadata": {
        "id": "xAg4mSSpYijq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions of functions"
      ],
      "metadata": {
        "id": "bBSJWZ52YnAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a wave data\n",
        "def load_wave_data(audio_dir, file_name):\n",
        "    file_path = os.path.join(audio_dir, file_name)\n",
        "    x, fs = librosa.load(file_path, sr=s_rate)\n",
        "    return x,fs\n",
        "\n",
        "\n",
        "# change wave data to mel-stft\n",
        "def calculate_melsp(x, sr, n_fft=1024, hop_length=128, n_mels=128):\n",
        "    stft = np.abs(librosa.stft(x, n_fft=n_fft, hop_length=hop_length))**2\n",
        "    melsp = librosa.feature.melspectrogram(S=stft, sr=sr, n_mels=n_mels)\n",
        "    log_melsp = librosa.power_to_db(melsp)\n",
        "    #print(log_melsp[:3])  # debug\n",
        "    return log_melsp\n",
        "\n",
        "\n",
        "# display wave in plots\n",
        "def show_wave(x):\n",
        "    plt.plot(x)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# display wave in heatmap\n",
        "def show_melsp(melsp, fs):\n",
        "    librosa.display.specshow(melsp, sr=fs)\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mquIlNVBYoIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "Fn6MxNl7Ytju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "x, fs = load_wave_data(audio_dir, meta_data.loc[0,\"file\"])\n",
        "\n",
        "# 5 sec default\n",
        "tmp = np.zeros(128 * int(np.ceil(3 * s_rate / n_mels)))\n",
        "for i in range(len(x)):\n",
        "  tmp[i] = x[i]\n",
        "melsp_tmp = calculate_melsp(tmp, s_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "show_wave(tmp)\n",
        "show_melsp(melsp_tmp, fs)\n",
        "\n",
        "melsp = calculate_melsp(x, s_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "\n",
        "np_data = np.zeros(128 * 345).reshape(128, 345)\n",
        "for m in range(melsp.shape[0]):\n",
        "    for n in range(melsp.shape[1]):\n",
        "      np_data[m][n] = melsp[m][n]\n",
        "show_wave(np_data)\n",
        "show_melsp(np_data, fs)\n",
        "\n",
        "print('wave size:', x.shape)\n",
        "print('melsp size:', melsp.shape)\n",
        "print('sampling rate:', fs)\n",
        "show_wave(x)\n",
        "show_melsp(melsp, fs)"
      ],
      "metadata": {
        "id": "7OWGUPB8YuiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipd.Audio(x, rate=fs)"
      ],
      "metadata": {
        "id": "wMEu785GYwVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training and test dataset"
      ],
      "metadata": {
        "id": "n7NLULRSbeSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get training dataset and target dataset\n",
        "filenames = meta_data.loc[:,\"file\"]\n",
        "targets = meta_data.loc[:, \"class_id\"]\n",
        "\n",
        "f_train, f_test, t_train, t_test = train_test_split(filenames, targets, test_size=0.15, stratify=targets)\n",
        "f_train = f_train.reset_index(drop=True)\n",
        "t_train = t_train.reset_index(drop=True)\n",
        "f_test = f_test.reset_index(drop=True)\n",
        "t_test = t_test.reset_index(drop=True)\n",
        "\n",
        "print('Number of data:')\n",
        "print('f_train:', f_train.shape[0])\n",
        "print('t_train:', t_train.shape[0])\n",
        "print('f_test:', f_test.shape[0])\n",
        "print('t_test:', t_test.shape[0])"
      ],
      "metadata": {
        "id": "SjXj_MGybfwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform wav data to mel-stft array"
      ],
      "metadata": {
        "id": "xyO4zLVIYxH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sec = 5\n",
        "freq = n_mels\n",
        "time = int(np.ceil(sec * s_rate / freq))\n",
        "print(sec, freq, time)"
      ],
      "metadata": {
        "id": "0MA0Cj6VYyZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save wave data in npz\n",
        "def save_np_data(filename, x, y):\n",
        "    np_data = np.zeros(freq*time*len(x)).reshape(len(x), freq, time)\n",
        "    np_targets = np.zeros(len(y))\n",
        "    for i in range(len(y)):\n",
        "        \n",
        "        _x, fs = load_wave_data(audio_dir, x[i])\n",
        "        \n",
        "        tmp = np.zeros(freq * time)\n",
        "        min_values = min(len(_x), len(tmp))\n",
        "        for j in range(min_values):\n",
        "          tmp[j] = _x[j]\n",
        "        \n",
        "        _x = calculate_melsp(tmp, s_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "        # for m in range(_x.shape[0]):\n",
        "        #   for n in range(_x.shape[1]):\n",
        "        #     np_data[i][m][n] = _x[m][n]\n",
        "        np_data[i] = _x[0:freq, 0:time]\n",
        "        np_targets[i] = y[i]\n",
        "    np.savez(filename, x=np_data, y=np_targets)  "
      ],
      "metadata": {
        "id": "-ygQPCXGYzeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "# save test dataset\n",
        "test_npz = 'custom{}_melsp_test_sr{}.npz'.format(n_classes, s_rate)\n",
        "save_np_data(test_npz, f_test, t_test)"
      ],
      "metadata": {
        "id": "Y4-OMnbzY0Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save raw training dataset\n",
        "train_npz= 'custom{}_melsp_train_sr{}.npz'.format(n_classes, s_rate)\n",
        "save_np_data(train_npz, f_train, t_train)"
      ],
      "metadata": {
        "id": "r0rg8Aw6Y174"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio classification with CNN"
      ],
      "metadata": {
        "id": "-Yn8QUcqY3Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "zo8ZfPlWY4Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters for CNN"
      ],
      "metadata": {
        "id": "F_UUVvS1Y6Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = t_train.shape[0]\n",
        "test_num = t_test.shape[0]"
      ],
      "metadata": {
        "id": "Wcnw6bJ2Y9Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "BHodV09TY9pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "data = np.load(train_npz)\n",
        "x_train = data[\"x\"]\n",
        "y_train = data[\"y\"]"
      ],
      "metadata": {
        "id": "IHUqxCJPY-rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load test dataset\n",
        "test_data = np.load(test_npz)\n",
        "x_test = test_data[\"x\"]\n",
        "y_test = test_data[\"y\"]\n",
        "#print(y_test[:5]) # debug"
      ],
      "metadata": {
        "id": "eYCqnDK9Y_hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine target data into one hot vector\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)\n",
        "#print(y_test[:5])  # debug"
      ],
      "metadata": {
        "id": "ZppCdyRHZAcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape training dataset\n",
        "x_train = x_train.reshape(train_num, freq, time, 1)\n",
        "x_test = x_test.reshape(test_num, freq, time, 1)"
      ],
      "metadata": {
        "id": "3kq03xlwZBep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('x_test:', x_test.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "metadata": {
        "id": "GKpiwaZLZCet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a CNN"
      ],
      "metadata": {
        "id": "7rZZH9RnZEhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models\n",
        "input_layer = layers.Input(shape=x_train.shape[1:])\n",
        "out = layers.Conv2D(32, (1,8), strides=(1,2), activation='relu', padding='same')(input_layer)\n",
        "out = layers.MaxPooling2D(pool_size=(1,4))(out)\n",
        "out = layers.Dropout(0.25)(out)\n",
        "out = layers.Conv2D(32, (8,1), strides=(2,1), activation='relu', padding='same')(out)\n",
        "out = layers.MaxPooling2D(pool_size=(4, 1))(out)\n",
        "out = layers.Dropout(0.25)(out)\n",
        "out = layers.Conv2D(64, (1,8), strides=(1,2), activation='relu', padding='same')(out)\n",
        "out = layers.MaxPooling2D(pool_size=(1,4))(out)\n",
        "out = layers.Dropout(0.25)(out)\n",
        "out = layers.Conv2D(64, (8,1), strides=(2,1), activation='relu', padding='same')(out)\n",
        "out = layers.MaxPooling2D(pool_size=(4, 1))(out)\n",
        "out = layers.Dropout(0.25)(out)\n",
        "out = layers.Flatten()(out)\n",
        "out = layers.Dense(64, activation='relu')(out)\n",
        "out = layers.Dropout(0.25)(out)\n",
        "out = layers.Dense(n_classes, activation='softmax')(out)\n",
        "\n",
        "model = models.Model(inputs=input_layer, outputs=out)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GPeQZeFH2QUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization and callbacks"
      ],
      "metadata": {
        "id": "Q3osurwyZHbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"/content/audio_classification/model-best.h5\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1)\n"
      ],
      "metadata": {
        "id": "Wm0CulfBZLlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exec training"
      ],
      "metadata": {
        "id": "WEEDkQXqZN13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train model\n",
        "batch_size = 16\n",
        "#epochs = 1000\n",
        "n_epochs = 100\n",
        "val_split = 0.2\n",
        "\n",
        "fit_log = model.fit(x_train, y_train,\n",
        "                    validation_split=val_split,\n",
        "                    epochs=n_epochs, batch_size=batch_size,\n",
        "                    verbose=1, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "model.load_weights(\"/content/audio_classification/model-best.h5\")"
      ],
      "metadata": {
        "id": "QBxw_i9NZPm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "Jy_Si6mJZQAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('loss=', score[0])\n",
        "print('accuracy=', score[1])"
      ],
      "metadata": {
        "id": "KuB0qvZlZR-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"plastic_bag_pop\", \"gun_shot\"]\n",
        "total_results = {}\n",
        "for i in range(40):\n",
        "  test_pred = model.predict(x_test)\n",
        "  true = []\n",
        "  pred = []\n",
        "  for i in range(y_test.shape[0]):\n",
        "    pred_idx = test_pred[i].argmax()\n",
        "    pred.append(classes[pred_idx])\n",
        "    true_idx = y_test[i].argmax()\n",
        "    true.append(classes[true_idx])\n",
        "\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "  display(pd.crosstab(true, pred))\n",
        "\n",
        "  total = 0\n",
        "  true_predict = 0\n",
        "  false_predict = 0\n",
        "\n",
        "  # for i in range(len(classes)):\n",
        "  #   print(f\"i: {i} = {classes[i]}\")\n",
        "\n",
        "  # print('Wrong prediction (file, true, pred):')\n",
        "  for i in range(y_test.shape[0]):\n",
        "      if pred[i] != true[i]:\n",
        "          # print(\"WRONG:\", f_test[i], true[i], pred[i], \"i = \", i)\n",
        "          false_predict += 1\n",
        "          if f_test[i] in total_results:\n",
        "            total_results[f_test[i]] -= 1\n",
        "          else:\n",
        "            total_results[f_test[i]] = 1\n",
        "      else:\n",
        "          # print(\"CORRECT:\", f_test[i], true[i], pred[i], \"i = \", i)\n",
        "          true_predict += 1\n",
        "          if f_test[i] in total_results:\n",
        "            total_results[f_test[i]] += 1\n",
        "          else:\n",
        "            total_results[f_test[i]] = 1\n",
        "    \n",
        "      total+= 1\n",
        "\n",
        "  print(f\"Total: {total}\\nCorrect: {true_predict}\\nWrong: {false_predict}\")\n",
        "\n",
        "sorted_results = sorted(total_results)\n",
        "for i in range(len(sorted_results)):\n",
        "  print(f\"{sorted_results[i]} - {total_results[sorted_results[i]]}\")\n",
        "print(len(sorted_results))"
      ],
      "metadata": {
        "id": "KEVKCMvDe5lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model and covert to ONNX"
      ],
      "metadata": {
        "id": "MEfpx_qmZvwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/audio_classification/model\")\n",
        "model.save_weights(\"/content/audio_classification/model.h5\")"
      ],
      "metadata": {
        "id": "k9SeDXyxZ1ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U tf2onnx"
      ],
      "metadata": {
        "id": "NrVJ0meQZ70c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m tf2onnx.convert --saved-model /content/audio_classification/model/ --output /content/audio_classification/model.onnx"
      ],
      "metadata": {
        "id": "wzon2hr0Z-YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r /content/audio_classification/model.zip /content/audio_classification/model/"
      ],
      "metadata": {
        "id": "uNDWeXC0aDzh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}